<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Cluster algorithm - Jijeng&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="jijeng" /><meta name="description" content="ä¸»è¦ä»‹ç»K-meansï¼ŒEMç®—æ³•å’ŒKNN ç®—æ³•ã€‚
" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.79.1 with theme even" />


<link rel="canonical" href="http://jijeng.github.io/post/cluster_algorithm/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.c7bc1becf36bcf6a9ebd25d2947e43a2eb745ddb0c9a32b43126fd7fa460c351.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Cluster algorithm" />
<meta property="og:description" content="ä¸»è¦ä»‹ç»K-meansï¼ŒEMç®—æ³•å’ŒKNN ç®—æ³•ã€‚
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://jijeng.github.io/post/cluster_algorithm/" />
<meta property="article:published_time" content="2020-04-18T10:34:04+08:00" />
<meta property="article:modified_time" content="2020-04-18T10:34:04+08:00" />
<meta itemprop="name" content="Cluster algorithm">
<meta itemprop="description" content="ä¸»è¦ä»‹ç»K-meansï¼ŒEMç®—æ³•å’ŒKNN ç®—æ³•ã€‚
">
<meta itemprop="datePublished" content="2020-04-18T10:34:04+08:00" />
<meta itemprop="dateModified" content="2020-04-18T10:34:04+08:00" />
<meta itemprop="wordCount" content="5118">



<meta itemprop="keywords" content="cluster,èšç±»," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cluster algorithm"/>
<meta name="twitter:description" content="ä¸»è¦ä»‹ç»K-meansï¼ŒEMç®—æ³•å’ŒKNN ç®—æ³•ã€‚
"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Jijeng&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Jijeng&#39;s Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Cluster algorithm</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-04-18 </span>
        <div class="post-category">
            <a href="/categories/machine-learning/"> machine learning </a>
            </div>
          <span class="more-meta"> çº¦ 5118 å­— </span>
          <span class="more-meta"> é¢„è®¡é˜…è¯» 11 åˆ†é’Ÿ </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">æ–‡ç« ç›®å½•</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#k-means-ç®—æ³•">K-means ç®—æ³•</a></li>
        <li><a href="#em-ç®—æ³•">EM ç®—æ³•</a></li>
        <li><a href="#knn">KNN</a></li>
        <li><a href="#nearest-neighbors">Nearest Neighbors</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>ä¸»è¦ä»‹ç»K-meansï¼ŒEMç®—æ³•å’ŒKNN ç®—æ³•ã€‚</p>
<img src="https://ftp.bmp.ovh/imgs/2020/04/c91ebad0e6203aa5.png" width="60%" height="60%">
<h2 id="k-means-ç®—æ³•">K-means ç®—æ³•</h2>
<p>K-means æ˜¯ä¸€ç§èšç±»ç®—æ³•ï¼Œå±äºæ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œå…ˆè¯´ä¸€ä¸‹ä»€ä¹ˆæ˜¯èšç±»ï¼šèšç±»åˆ†ææ˜¯åœ¨æ•°æ®ä¸­å‘ç°æ•°æ®å¯¹è±¡ä¹‹é—´çš„å…³ç³»ï¼Œå°†æ•°æ®è¿›è¡Œåˆ†ç»„ï¼Œç»„å†…çš„ç›¸ä¼¼æ€§è¶Šå¤§ï¼Œç»„é—´çš„å·®åˆ«è¶Šå¤§ï¼Œåˆ™èšç±»æ•ˆæœè¶Šå¥½ã€‚</p>
<p>K-Meansç®—æ³•æ€æƒ³ï¼šå¯¹ç»™å®šçš„æ ·æœ¬é›†ï¼Œäº‹å…ˆç¡®å®šèšç±»ç°‡æ•°K ï¼ˆè¶…å‚æ•°ï¼‰ï¼Œè®©ç°‡å†…çš„æ ·æœ¬å°½å¯èƒ½ç´§å¯†åˆ†å¸ƒåœ¨ä¸€èµ·ï¼Œä½¿ç°‡é—´çš„è·ç¦»å°½å¯èƒ½å¤§ã€‚è¯¥ç®—æ³•è¯•å›¾ä½¿é›†ç¾¤æ•°æ®åˆ†ä¸ºnç»„ç‹¬ç«‹æ•°æ®æ ·æœ¬ï¼Œä½¿nç»„é›†ç¾¤é—´çš„æ–¹å·®ç›¸ç­‰ï¼Œæ•°å­¦æè¿°ä¸ºæœ€å°åŒ–æƒ¯æ€§æˆ–é›†ç¾¤å†…çš„å¹³æ–¹å’Œã€‚K-Meansä½œä¸ºæ— ç›‘ç£çš„èšç±»ç®—æ³•ï¼Œå®ç°è¾ƒç®€å•ï¼Œèšç±»æ•ˆæœå¥½ï¼Œå› æ­¤è¢«å¹¿æ³›ä½¿ç”¨ã€‚</p>
<p><strong>ç®—æ³•æ­¥éª¤</strong></p>
<ol>
<li>åˆ›å»ºkä¸ªç‚¹ä½œä¸ºkä¸ªç°‡çš„èµ·å§‹è´¨å¿ƒï¼ˆç»å¸¸éšæœºé€‰æ‹©ï¼‰ã€‚</li>
<li>åˆ†åˆ«è®¡ç®—å‰©ä¸‹çš„å…ƒç´ åˆ°kä¸ªç°‡ä¸­å¿ƒçš„ç›¸å¼‚åº¦ï¼ˆè·ç¦»ï¼‰ï¼Œå°†è¿™äº›å…ƒç´ åˆ†åˆ«åˆ’å½’åˆ°ç›¸å¼‚åº¦æœ€ä½çš„ç°‡ã€‚</li>
<li>æ ¹æ®èšç±»ç»“æœï¼Œé‡æ–°è®¡ç®—kä¸ªç°‡å„è‡ªçš„ä¸­å¿ƒï¼Œè®¡ç®—æ–¹æ³•æ˜¯å–ç°‡ä¸­æ‰€æœ‰å…ƒç´ å„è‡ªç»´åº¦çš„ç®—æœ¯å¹³å‡å€¼ã€‚</li>
<li>å°†Dä¸­å…¨éƒ¨å…ƒç´ æŒ‰ç…§æ–°çš„ä¸­å¿ƒé‡æ–°èšç±»ã€‚</li>
<li>é‡å¤ç¬¬4æ­¥ï¼Œç›´åˆ°èšç±»ç»“æœä¸å†å˜åŒ–ã€‚</li>
<li>æœ€åï¼Œè¾“å‡ºèšç±»ç»“æœã€‚</li>
</ol>
<p><strong>K-Meansç®—æ³•ä¼˜ç¼ºç‚¹</strong></p>
<p>ä¼˜ç‚¹</p>
<ol>
<li>åŸç†æ˜“æ‡‚ã€æ˜“äºå®ç°ï¼›</li>
<li>å½“ç°‡é—´çš„åŒºåˆ«è¾ƒæ˜æ˜¾æ—¶ï¼Œèšç±»æ•ˆæœè¾ƒå¥½ï¼›</li>
<li>Trains quickly</li>
</ol>
<p>ç¼ºç‚¹</p>
<ol>
<li>å½“æ ·æœ¬é›†è§„æ¨¡å¤§æ—¶ï¼Œæ”¶æ•›é€Ÿåº¦ä¼šå˜æ…¢ï¼›</li>
<li>å¯¹å™ªå£°æˆ–è€…ç¦»ç¾¤ç‚¹æ¯”è¾ƒæ•æ„Ÿ</li>
<li>kçš„å–å€¼ååˆ†å…³é”®ï¼Œå¯¹ä¸åŒæ•°æ®é›†ï¼Œké€‰æ‹©æ²¡æœ‰å‚è€ƒæ€§ï¼Œéœ€è¦å¤§é‡å®éªŒ</li>
<li>åˆå§‹è´¨å¿ƒçš„é€‰æ‹©ï¼Œä¸åŒçš„è´¨å¿ƒé€‰æ‹©å¯èƒ½å¾—åˆ°å®Œå…¨ä¸åŒçš„ç»“æœï¼Œå› ä¸ºk-means å¯ä»¥ä¿è¯çš„æ˜¯å±€éƒ¨æœ€ä¼˜è§£ï¼Œè€Œä¸æ˜¯å…¨å±€æœ€ä¼˜è§£ã€‚é’ˆå¯¹è¯¥ç¼ºé™·ï¼Œå¯ä»¥ä½¿ç”¨ kmeans++ ç®—æ³•è§£å†³ã€‚k-means++ ç®—æ³•é€‰æ‹©seedsçš„åŸºæœ¬æ€è·¯æ˜¯ï¼šåˆå§‹åŒ–èšç±»ä¸­å¿ƒä¹‹é—´çš„ç›¸äº’è·ç¦»è¦å°½å¯èƒ½çš„è¿œã€‚</li>
</ol>
<p><strong>æ—¶é—´å¤æ‚åº¦</strong>
$O(mnkt)$ï¼Œ å…¶ä¸­$t$ ä¸ºè¿­ä»£åˆºæ‰‹ï¼Œ $k$ ä¸ºç°‡çš„æ•°ç›®ï¼Œ $m$ ä¸ºæ•°æ®é‡, $n$ ä¸ºæ•°æ®çš„ç»´åº¦ã€‚å¯¹äºå¤§æ•°æ®æ¥è¯´ï¼Œ$t$ï¼Œ$k$å’Œ$n$ éƒ½æ˜¯å¯ä»¥çœ‹åšå¸¸æ•°ï¼Œé‚£ä¹ˆæ—¶é—´å¤æ‚åº¦è¿‘ä¼¼å°±æ˜¯ $O(n)$ï¼Œæ‰€ä»¥è¯¥ç®—æ³•æ˜¯ç›¸å½“é«˜æ•ˆçš„ã€‚</p>
<p><strong>ç©ºé—´å¤æ‚åº¦</strong>
$O(m+k)n$ å…¶ä¸­ $k$ ä¸ºç°‡çš„æ•°ç›®ï¼Œ $m$ä¸ºæ•°æ®é‡ï¼Œ $n$ ä¸ºæ•°æ®çš„ç»´åº¦ã€‚åŒç†å¯¹äºç©ºé—´å¤æ‚åº¦ä¹Ÿå¯ä»¥è¿™æ ·åˆ†æã€‚
æœ€åçš„ç»“è®ºå¯ä»¥ç®€åŒ–ä¸ºï¼šæ—¶ç©ºå¤æ‚åº¦æ˜¯$O(n)$</p>
<ul>
<li>
<p>Hard clustering: Even though some colors near the boundary are pretty similar, but they are grouped into different clusters. No red/green/blue can cross the line.</p>
</li>
<li>
<p>Means/latent variables: the labels are added manually based on the means (the cross). K-means will end up with bunches of means and assignments, but how to interpret the means are up to people.</p>
</li>
</ul>
<p>You may notice the issues that k-means have:</p>
<ul>
<li>Initialization matters: the same k may end up with different outcomes, because initialization matters. Itâ€™s also important to break the tie.</li>
<li>Unstable under this uniform-ish circumstance. There is no clear structure to divide them into groups.</li>
</ul>
<p><strong>Choosing K</strong></p>
<p>The algorithm explained above finds clusters for the number k that we chose. So, how do we decide on that number?</p>
<p>å°è¯•æ³•ï¼š è®¡ç®—æ¯ä¸ªç‚¹åˆ°æœ€è¿‘çš„ç°‡çš„è·ç¦»çš„æ€»å’Œï¼Œå¦‚æœå¢åŠ  k å¯¼è‡´çš„æ€»å’Œä¸‹é™ä¸æ˜æ˜¾ï¼Œé‚£ä¹ˆå°±æ¥è¿‘ä¸´ç•Œç‚¹äº†ã€‚</p>
<p>To find the best k we need to measure the quality of the clusters. The most traditional and straightforward method is to start with a random k, create centroids, and run the algorithm as we explained above. A sum is given based on the distances between each point and its closest centroid. As an increase in clusters correlates with smaller groupings and distances, this sum will always decrease when k increases; as an extreme example, if we choose a k value that is equal to the number of data points that we have, the sum will be zero.</p>
<p>The goal with this process is to find the point at which increasing k will cause a very small decrease in the error sum, while decreasing k will sharply increase the error sum. This sweet spot is called the â€œelbow point.â€  In the image below, it is clear that the â€œelbowâ€ point is at k-3.Â­</p>
<p><img src="https://i.bmp.ovh/imgs/2019/07/8b4f6493ed14471b.png" alt=""></p>
<p>ä½¿ç”¨åœºæ™¯ï¼šä¸€èˆ¬åœ¨æ•°æ®åˆ†æçš„å‰æœŸä½¿ç”¨ï¼Œé€‰æ‹©é€‚å½“çš„ $K$ï¼Œåˆ†æä¸åŒèšç±»æ•°æ®ä¸‹çš„ç‰¹ç‚¹ã€‚</p>
<p>k-means æ˜¯ä»¥æ¬§å¼è·ç¦»ä½œä¸ºç›¸ä¼¼åº¦æµ‹é‡ï¼Œè¦æ±‚æŸä¸€åˆå§‹åŒ–èšç±»ä¸­å¿ƒåˆ†ç±»æ•ˆæœæœ€å¥½ã€‚ç®—æ³•é‡‡ç”¨è¯¯å·®å¹³æ–¹å’Œä½œä¸ºå‡†ä¾§å‡½æ•°ï¼Œä¼˜åŒ–çš„æ˜¯è¯¥å‡½æ•°ã€‚</p>
<p>æ¬§å¼è·ç¦»å’Œæ›¼å“ˆé¡¿è·ç¦»ï¼ˆL1è·ç¦»ï¼‰éƒ½å¯ä»¥è¡¨ç¤ºæœ€è¿‘é‚»å±…ä¹‹é—´çš„è·ç¦»ï¼Œå¦‚ä½•è¿›è¡Œé€‰æ‹©ï¼Ÿå‰è€…é€‚åˆåœ¨å½’ä¸€åŒ–æ— é‡çº²çš„æƒ…å†µä¸‹è¿›è¡Œä½¿ç”¨ï¼Œä¸¤è€…ä¸å…·æœ‰ç›¸äº’æ›¿ä»£æ€§ã€‚</p>
<p><strong>ä»£ç å®ç°</strong></p>
<p>è‡ªå·±å®ç°äº†ä¸€ä¸ª k-means è®¡ç®—è¿‡ç¨‹ï¼›ç„¶åä½¿ç”¨ sklearn ä¸­å®ç°å¥½çš„æ¡†æ¶ã€‚æ²¡æœ‰æ¯”è¿™ä¸ªå†™å¾—æ›´å¥½çš„äº†ã€‚ä»£ç <a href="http://benalexkeen.com/k-means-clustering-in-python/">é“¾æ¥</a></p>
<p>ä»£ç æ‘˜è¦</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">## Initialisation</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">69</span><span class="p">,</span> <span class="mi">72</span><span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">39</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">46</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">58</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">24</span><span class="p">]</span>
<span class="p">})</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1"># centroids[i] = [x, y]</span>
<span class="c1"># å­¦ä¹ å¼€æºä»£ç ï¼Œåœ¨äºå‘åˆ«äººå­¦ä¹ ï¼Œçœ‹äººå®¶æ˜¯å¦‚ä½•å†™ä»£ç çš„ï¼Œæ€ä¹ˆå†™å¾—ç®€å•é«˜æ•ˆï¼Œæ¼‚äº®</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="p">}</span>
    
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">colmap</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colmap</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">assignment</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">centroids</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># sqrt((x1 - x2)^2 - (y1 - y2)^2)</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;distance_from_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
                <span class="o">+</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="n">centroid_distance_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;distance_from_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">centroid_distance_cols</span><span class="p">]</span><span class="o">.</span><span class="n">idxmin</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="c1">#å¾—åˆ°çš„æ˜¯id æ ‡è¯†</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s1">&#39;distance_from_&#39;</span><span class="p">)))</span> <span class="c1"># è¿™ä¸ªè½¬æ¢æˆæ•°å­—</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">colmap</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="c1"># æ³¨æ„lambda å‡½æ•° x æ˜¯è¾“å…¥å‚æ•°ï¼Œ: ä¹‹åæ˜¯å¤„ç†çš„å‡½æ•°</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">assignment</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">centroids</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">## Update Stage</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="n">old_centroids</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
        <span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">k</span>

<span class="n">centroids</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="c1"># è¿™ä¸ªå¯è§†åŒ–çš„ç®­å¤´ä¹Ÿæ˜¯åšå¾—ç›¸å½“çš„æ£’</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colmap</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">old_centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">old_x</span> <span class="o">=</span> <span class="n">old_centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">old_y</span> <span class="o">=</span> <span class="n">old_centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">old_centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mf">0.75</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="p">(</span><span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">old_centroids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="mf">0.75</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">old_x</span><span class="p">,</span> <span class="n">old_y</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">colmap</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ec</span><span class="o">=</span><span class="n">colmap</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Continue until all assigned categories don&#39;t change any more</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">closest_centroids</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">assignment</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">centroids</span><span class="p">)</span>
    <span class="c1"># ä¸åŒçš„è¯­è¨€ä¹‹é—´æ˜¯ç›¸åŒçš„ï¼Œè¦ä¹ˆæ˜¯å€¼æ¯”è¾ƒï¼Œé‚£ä¹ˆæ˜¯å¼•ç”¨æ¯”è¾ƒï¼Œæ˜¾ç„¶è¿™é‡Œæ˜¯å€¼æ¯”è¾ƒ</span>
    <span class="k">if</span> <span class="n">closest_centroids</span><span class="o">.</span><span class="n">equals</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;closest&#39;</span><span class="p">]):</span>
        <span class="k">break</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colmap</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="c1"># å¦‚æ„å¯ä»¥ä¼ å…¥ä¸€ä¸ªlistï¼Œè¡¨ç¤ºä¸¤ä¸ªå‚æ•°</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="em-ç®—æ³•">EM ç®—æ³•</h2>
<p><strong>å…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡</strong></p>
<p>äº‹ä»¶å‘ç”Ÿå‰çš„é¢„åˆ¤æ¦‚ç‡ã€‚å¯ä»¥æ˜¯åŸºäºå†å²æ•°æ®çš„ç»Ÿè®¡ï¼Œå¯ä»¥ç”±èƒŒæ™¯å¸¸è¯†å¾—å‡ºï¼Œä¹Ÿå¯ä»¥æ˜¯äººçš„ä¸»è§‚è§‚ç‚¹ç»™å‡ºã€‚ä¸€èˆ¬éƒ½æ˜¯å•ç‹¬äº‹ä»¶æ¦‚ç‡ï¼Œå¦‚ $P(x) $, $P(y)$ã€‚äº‹ä»¶å‘ç”Ÿåæ±‚çš„åå‘æ¡ä»¶æ¦‚ç‡ï¼›æˆ–è€…è¯´ï¼ŒåŸºäºå…ˆéªŒæ¦‚ç‡æ±‚å¾—çš„åå‘æ¡ä»¶æ¦‚ç‡ã€‚æ¡ä»¶æ¦‚ç‡ï¼šä¸€ä¸ªäº‹ä»¶å‘ç”Ÿåå¦ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ã€‚</p>
<p>å…ˆéªŒæ¦‚ç‡æ˜¯æŒ‡æ ¹æ®ä»¥å¾€ç»éªŒå’Œåˆ†æå¾—åˆ°çš„æ¦‚ç‡,å®ƒå¾€å¾€ä½œä¸º&quot;ç”±å› æ±‚æœ&quot;é—®é¢˜ä¸­çš„&quot;å› &quot;å‡ºç°ï¼Œæ¯”å¦‚å…¨æ¦‚ç‡å…¬å¼ã€‚</p>
<p>åéªŒæ¦‚ç‡æ˜¯æŒ‡ä¾æ®å¾—åˆ°&quot;ç»“æœ&quot;ä¿¡æ¯æ‰€è®¡ç®—å‡ºçš„æœ€æœ‰å¯èƒ½æ˜¯é‚£ç§äº‹ä»¶å‘ç”Ÿ,å¦‚è´å¶æ–¯å…¬å¼ä¸­çš„,æ˜¯&quot;æ‰§æœå¯»å› &quot;é—®é¢˜ä¸­çš„&quot;å› &quot;ï¼Œ æ¯”å¦‚è´å¶æ–¯å…¬å¼ã€‚</p>
<p><strong>æå¤§ä¼¼ç„¶ä¼°è®¡</strong></p>
<p>æå¤§ä¼¼ç„¶ä¼°è®¡æ˜¯ç”¨æ¥æ±‚è§£æ¦‚ç‡åˆ†å¸ƒä¸­å‚æ•°å€¼ã€‚ä¸ºä»€ä¹ˆè¦æ±‚è§£å‚æ•°å€¼ï¼Ÿå› ä¸ºå¤§å¤šæ•°æ¦‚ç‡åˆ†å¸ƒéƒ½æ˜¯ç”±å…³é”®çš„å‚æ•°å€¼ï¼Œ å¾—åˆ°åˆ†å¸ƒå°±å¯ä»¥è®¡ç®—æ¦‚ç‡å€¼ï¼Œé‚£ä¹ˆè¿›è¡Œåˆ†ç±»å’Œå›å½’å°±æ²¡æœ‰ä»€ä¹ˆé—®é¢˜ã€‚å¸¸è§çš„æ¦‚ç‡åˆ†å¸ƒæ¯”å¦‚äºŒé¡¹åˆ†å¸ƒæ˜¯ç”± $p $æ§åˆ¶ï¼Œæ­£å¤ªåˆ†å¸ƒæ˜¯ç”± $\mu$  å’Œ$\sigma$æ§åˆ¶ã€‚æå¤§ä¼¼ç„¶ä¼°è®¡ç†è®ºè®¤ä¸ºï¼Œæ¦‚ç‡è¶Šå¤§ï¼Œå‘ç”Ÿçš„å¯èƒ½æ€§å°±è¶Šå¤§ã€‚</p>
<p>è¯¥ç®—æ³•èƒŒæ™¯ï¼š</p>
<ol>
<li>æœ‰ä¸€ä¸ªç‹¬ç«‹åŒåˆ†å¸ƒçš„æ ·æœ¬é›† Dï¼Œä¸”æ ·æœ¬ä»æ•°æ®åˆ†å¸ƒ $p(x | \theta)$ ä¸­æŠ½å–</li>
<li>æƒ³è¦è®¡ç®— $\theta$</li>
</ol>
<p>è§£å†³æ€è·¯ï¼š</p>
<ol>
<li>å‡è®¾ D ä¸­æ‰€æœ‰çš„æ ·æœ¬éƒ½æ˜¯ç‹¬ç«‹ä» $ p(x | \theta)$ ä¸­æŠ½å–ï¼Œé‚£ä¹ˆï¼š</li>
</ol>
<p>$$
P({X=x^{1}, X=x^{2}, \cdots, X=x^{n}})=\prod_{i=1}^{n} p(x^{i} | {\theta})
$$</p>
<p>è®°ç­‰å·åé¢çš„å¼å­ä¸ºä¼¼ç„¶å‡½æ•°</p>
<ol start="2">
<li>å› ä¸ºä¹˜ç§¯ä¸æ–¹ä¾¿å¤„ç†ï¼Œæ‰€ä»¥ä¸Šé¢å¼å­ä¸­å·¦å³ä¸¤è¾¹æ±‚å¯¹æ•°</li>
</ol>
<p>$$
\ln l(\boldsymbol{\theta})=\ln \prod_{i=1}^{n} p\left(x^{i} | \boldsymbol{\theta}\right)=\sum_{i=1}^{n} \ln p\left(x^{i} | \boldsymbol{\theta}\right)
$$</p>
<p>æ ¹æ®ç®—æ³•çš„æ€æƒ³ï¼Œæˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ– $L(\theta)$ï¼Œ æœ€å¤§åŒ–çš„ $\theta$ å°±æ˜¯æˆ‘ä»¬è¦æ±‚çš„ã€‚å¦‚ä½•æœ€å¤§åŒ– $L(\theta)$ï¼Ÿä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœå¦‚æœåªæœ‰ä¸€ä¸ªå‚æ•°ï¼Œæ¯”å¦‚äºŒé¡¹åˆ†å¸ƒï¼Œé‚£ä¹ˆæ±‚å¯¼ä»¤å¯¼æ•°ä¸º0 å°±å¯ä»¥æ±‚$\theta$ã€‚å¦‚æœæœ‰å¤šä¸ªå‚æ•°ï¼Œæ¯”å¦‚æ­£å¤ªåˆ†å¸ƒï¼Œé‚£ä¹ˆå°±éœ€è¦æ±‚è§£åå¯¼ï¼Œ ä»¤åå¯¼æ•°ä¸º0.</p>
<p>æå¤§ä¼¼ç„¶ä¼°è®¡çš„å±€é™æ€§</p>
<ul>
<li>éœ€è¦äº‹å…ˆå‡å®šæ•°æ®åˆ†å¸ƒ</li>
<li>å‡å®šçš„æ•°æ®åˆ†å¸ƒå’ŒçœŸå®çš„æ•°æ®åˆ†å¸ƒä¸ä¸€è‡´çš„æ—¶å€™ï¼Œå®¹æ˜“å‡ºç°è¾ƒå¤§çš„è¯¯å·®</li>
</ul>
<p>ä»‹ç»å®Œäº†æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œé‚£ä¹ˆåé¢æ˜¯çœŸæ­£ EM ï¼ˆExpectation Maximization Algorithmï¼‰ç®—æ³•ã€‚</p>
<p>EMç®—æ³•è§£å†³è¿™ä¸ªçš„æ€è·¯æ˜¯ä½¿ç”¨å¯å‘å¼çš„è¿­ä»£æ–¹æ³•ï¼Œæ—¢ç„¶æˆ‘ä»¬æ— æ³•ç›´æ¥æ±‚å‡ºæ¨¡å‹åˆ†å¸ƒå‚æ•°ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å…ˆçŒœæƒ³éšå«æ•°æ®ï¼ˆEMç®—æ³•çš„Eæ­¥ï¼‰ï¼Œæ¥ç€åŸºäºè§‚å¯Ÿæ•°æ®å’ŒçŒœæµ‹çš„éšå«æ•°æ®ä¸€èµ·æ¥æå¤§åŒ–å¯¹æ•°ä¼¼ç„¶ï¼Œæ±‚è§£æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ï¼ˆEMç®—æ³•çš„Mæ­¥)ã€‚ç”±äºæˆ‘ä»¬ä¹‹å‰çš„éšè—æ•°æ®æ˜¯çŒœæµ‹çš„ï¼Œæ‰€ä»¥æ­¤æ—¶å¾—åˆ°çš„æ¨¡å‹å‚æ•°ä¸€èˆ¬è¿˜ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç»“æœã€‚ä¸è¿‡æ²¡å…³ç³»ï¼Œæˆ‘ä»¬åŸºäºå½“å‰å¾—åˆ°çš„æ¨¡å‹å‚æ•°ï¼Œç»§ç»­çŒœæµ‹éšå«æ•°æ®ï¼ˆEMç®—æ³•çš„Eæ­¥ï¼‰ï¼Œç„¶åç»§ç»­æå¤§åŒ–å¯¹æ•°ä¼¼ç„¶ï¼Œæ±‚è§£æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ï¼ˆEMç®—æ³•çš„Mæ­¥)ã€‚ä»¥æ­¤ç±»æ¨ï¼Œä¸æ–­çš„è¿­ä»£ä¸‹å»ï¼Œç›´åˆ°æ¨¡å‹åˆ†å¸ƒå‚æ•°åŸºæœ¬æ— å˜åŒ–ï¼Œç®—æ³•æ”¶æ•›ï¼Œæ‰¾åˆ°åˆé€‚çš„æ¨¡å‹å‚æ•°ã€‚ä»ä¸Šé¢çš„æè¿°å¯ä»¥çœ‹å‡ºï¼ŒEMç®—æ³•æ˜¯è¿­ä»£æ±‚è§£æœ€å¤§å€¼çš„ç®—æ³•ï¼ŒåŒæ—¶ç®—æ³•åœ¨æ¯ä¸€æ¬¡è¿­ä»£æ—¶åˆ†ä¸ºä¸¤æ­¥ï¼ŒEæ­¥å’ŒMæ­¥ã€‚ä¸€è½®è½®è¿­ä»£æ›´æ–°éšå«æ•°æ®å’Œæ¨¡å‹åˆ†å¸ƒå‚æ•°ï¼Œç›´åˆ°æ”¶æ•›ï¼Œå³å¾—åˆ°æˆ‘ä»¬éœ€è¦çš„æ¨¡å‹å‚æ•°ã€‚ä¸€ä¸ªæœ€ç›´è§‚äº†è§£EMç®—æ³•æ€è·¯çš„æ˜¯K-Meansç®—æ³•ï¼Œè§ä¹‹å‰å†™çš„K-Meansèšç±»ç®—æ³•åŸç†ã€‚åœ¨K-Meansèšç±»æ—¶ï¼Œæ¯ä¸ªèšç±»ç°‡çš„è´¨å¿ƒæ˜¯éšå«æ•°æ®ã€‚æˆ‘ä»¬ä¼šå‡è®¾$ğ¾$ä¸ªåˆå§‹åŒ–è´¨å¿ƒï¼Œå³EMç®—æ³•çš„Eæ­¥ï¼›ç„¶åè®¡ç®—å¾—åˆ°æ¯ä¸ªæ ·æœ¬æœ€è¿‘çš„è´¨å¿ƒï¼Œå¹¶æŠŠæ ·æœ¬èšç±»åˆ°æœ€è¿‘çš„è¿™ä¸ªè´¨å¿ƒï¼Œå³EMç®—æ³•çš„Mæ­¥ã€‚é‡å¤è¿™ä¸ªEæ­¥å’ŒMæ­¥ï¼Œç›´åˆ°è´¨å¿ƒä¸å†å˜åŒ–ä¸ºæ­¢ï¼Œè¿™æ ·å°±å®Œæˆäº†K-Meansèšç±»ã€‚</p>
<ol>
<li>
<p>EMç®—æ³•èƒ½ä¿è¯æ”¶æ•›å—ï¼Ÿ
æœ‰å……åˆ†çš„ç†è®ºè¯´æ˜ï¼Œè¿™ä¸ªæ˜¯èƒ½å¤Ÿä¿è¯æ”¶æ•›çš„ã€‚</p>
</li>
<li>
<p>EMç®—æ³•å¦‚æœæ”¶æ•›ï¼Œé‚£ä¹ˆèƒ½ä¿è¯æ”¶æ•›åˆ°å…¨å±€æœ€å¤§å€¼å—ï¼Ÿ<br>
ä¸èƒ½ä¿è¯ï¼Œè¿™ä¸ªå–å†³äºåˆå§‹åŒ–ã€‚åˆå§‹å€¼ä¸åŒï¼Œé‚£ä¹ˆæœ€åçš„ç»“æœä¸åŒã€‚æ‰€ä»¥è¿™ä¸ªæ˜¯ç»™å®šåˆå§‹å€¼ï¼Œç»è¿‡å¾ªç¯è¿­ä»£ï¼Œæœ€ç»ˆé€¼è¿‘çœŸå®å€¼ã€‚</p>
</li>
</ol>
<p>å¦‚æœè¦è®²è§£ EM ç®—æ³•ï¼Œå¯ä»¥è®¤ä¸º K-means æ˜¯å…¶ä¸€ä¸ªç‰¹ä¾‹ï¼Œé‚£ä¹ˆè¿›è¡Œç†è§£ã€‚</p>
<p>PROPERTIES</p>
<ul>
<li>Soft clustering: can cluster data with no clear group structure; easy to interpret responsibility as probability or componence percentage.</li>
<li>Convergence: non-decreasing log likelihood indicates that with more iterations, EM is guaranteed to get a better result. I.e., it is guaranteed to converge to one of local optima.</li>
<li>More computation &amp; risks:
It requires moooore computation than k-means, moooore iterations to converge, but
still possible to get stuck in local optima. When that happens, there is something you can do:</li>
<li>Cry</li>
<li>Random restart</li>
</ul>
<p>Relationship btwn k-means &amp; EM</p>
<blockquote>
<p>There is a close similarity between k-means algorithm and EM algorithm for GMM. The first way to understand is from the two-stage update process. Both of the algorithms share an expectation stage and a maximization stage.
The second way is we can derive the k-means as a particular limit EM for GMM. The key is to make the soft assignment to be a hard one. We can simply use a \arg \max  to force the probabilities to be binary, or consider a GMM setting with covariance matrix to be $\epsilon$ I where $\lim\epsilon \rightarrow 0$.</p>
</blockquote>
<h2 id="knn">KNN</h2>
<p>Kæœ€è¿‘é‚»(k-Nearest Neighborï¼ŒKNN) æ˜¯æœ‰ç›‘ç£åˆ†ç±»å­¦ä¹ ï¼Œæ ¹æ®K ä¸ªæœ€è¿‘é‚»çš„ç±»åˆ«ä¿¡æ¯ï¼Œé€šè¿‡æŠ•ç¥¨çš„æ–¹å¼å†³å®šåˆšè¿›æ¥çš„æ•°æ®ç‚¹çš„ç±»åˆ«ã€‚å’ŒKNN å®¹æ˜“ç›¸æ··æ·†çš„æ˜¯K-meansç®—æ³•ï¼Œå…·ä½“å¯ä»¥å‚è€ƒä¸Šé¢çš„æè¿°ã€‚KNN ä¸­çš„K è¡¨ç¤ºKä¸ªæœ€è¿‘é‚»æ˜¯æœ‰æŠ•ç¥¨æƒçš„ï¼Œæ ¹æ®K ä¸ªæœ€è¿‘é‚»çš„æŠ•ç¥¨ç„¶åå†³å®šæ–°åŠ å…¥çš„ç‚¹ç±»åˆ«ä¿¡æ¯ã€‚</p>
<p>In short, the algorithms are trying to accomplish different goals. K-nearest neighbor is a subset of supervised learning classification (or regression) algorithms (it takes a bunch of labeled points and uses them to learn how to label other points). It is supervised because you are trying to classify a point based on the known classification of other points. In contrast, K-means is a subset of unsupervised learning clustering algorithms (it takes a bunch of unlabeled points and tries to group them into clusters). It is unsupervised because the points have no external classification.</p>
<p>The $ k $ in each case mean different things. In K-NN, the $ k $ represents the number of neighbors who have a vote in determining a new playerâ€™s position. The $ k $ in K-means, determine the number of clusters we want to end up.</p>
<p>In a K-NN algorithm, a test sample is given as the class of majority of its nearest neighbours. For example, if we have three classes and the goal is to find a class label for the unknown example $ x_j $ then, by using the Euclidean distance and a value of $ k=5 $ neighbors, the unknown sample is classified to the category of the most voted neighbors.</p>
<blockquote>
<p>How it works?
Step 1: Determine the value for K
Step 2: Calculate the distances between the new input (test data) and all the training data. The most commonly used metrics for calculating distance are Euclidean, Manhattan and Minkowski
Step 3: Sort the distance and determine k nearest neighbors based on minimum distance values
Step 4: Analyze the category of those neighbors and assign the category for the test data based on majority vote
Step 5: Return the predicted class</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g44zy5fny9j209i08sdh1.jpg" alt=""></p>
<p>The situation with K-means is that, given some data you will cluster them in k-groups or clusters. The initial step of the algorithm is to randomly spawn $ k $ centroids (centers). At every iteration the center of each cluster is moved slightly to minimize the objective function. The algorithm will terminate if the iterations are maximized or if the centroids stop to move.</p>
<p>The objective function of K-means is $ J = \sum_{j=1}^{k}\sum_{i=1}^{n}\left |x_i^{j}-c_j  \right |^{2} $</p>
<blockquote>
<p>How it works?
Step 1: Determine K value by Elbow method and specify the number of clusters K
Step 2: Randomly assign each data point to a cluster
Step 3: Determine the cluster centroid coordinates
Step 4: Determine the distances of each data point to the centroids and re-assign each point to the closest cluster centroid based upon minimum distance
Step 5: Calculate cluster centroids again
Step 6: Repeat steps 4 and 5 until we reach global optima where no improvements are possible and no switching of data points from one cluster to other.</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g44zwyhj76j20fz0av3zf.jpg" alt=""></p>
<p>ã€€ä¸Šå›¾aè¡¨è¾¾äº†åˆå§‹çš„æ•°æ®é›†ï¼Œå‡è®¾k=2ã€‚åœ¨å›¾bä¸­ï¼Œæˆ‘ä»¬éšæœºé€‰æ‹©äº†ä¸¤ä¸ªkç±»æ‰€å¯¹åº”çš„ç±»åˆ«è´¨å¿ƒï¼Œå³å›¾ä¸­çš„çº¢è‰²è´¨å¿ƒå’Œè“è‰²è´¨å¿ƒï¼Œç„¶ååˆ†åˆ«æ±‚æ ·æœ¬ä¸­æ‰€æœ‰ç‚¹åˆ°è¿™ä¸¤ä¸ªè´¨å¿ƒçš„è·ç¦»ï¼Œå¹¶æ ‡è®°æ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«ä¸ºå’Œè¯¥æ ·æœ¬è·ç¦»æœ€å°çš„è´¨å¿ƒçš„ç±»åˆ«ï¼Œå¦‚å›¾cæ‰€ç¤ºï¼Œç»è¿‡è®¡ç®—æ ·æœ¬å’Œçº¢è‰²è´¨å¿ƒå’Œè“è‰²è´¨å¿ƒçš„è·ç¦»ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æ‰€æœ‰æ ·æœ¬ç‚¹çš„ç¬¬ä¸€è½®è¿­ä»£åçš„ç±»åˆ«ã€‚æ­¤æ—¶æˆ‘ä»¬å¯¹æˆ‘ä»¬å½“å‰æ ‡è®°ä¸ºçº¢è‰²å’Œè“è‰²çš„ç‚¹åˆ†åˆ«æ±‚å…¶æ–°çš„è´¨å¿ƒï¼Œå¦‚å›¾4æ‰€ç¤ºï¼Œæ–°çš„çº¢è‰²è´¨å¿ƒå’Œè“è‰²è´¨å¿ƒçš„ä½ç½®å·²ç»å‘ç”Ÿäº†å˜åŠ¨ã€‚å›¾eå’Œå›¾fé‡å¤äº†æˆ‘ä»¬åœ¨å›¾cå’Œå›¾dçš„è¿‡ç¨‹ï¼Œå³å°†æ‰€æœ‰ç‚¹çš„ç±»åˆ«æ ‡è®°ä¸ºè·ç¦»æœ€è¿‘çš„è´¨å¿ƒçš„ç±»åˆ«å¹¶æ±‚æ–°çš„è´¨å¿ƒã€‚æœ€ç»ˆæˆ‘ä»¬å¾—åˆ°çš„ä¸¤ä¸ªç±»åˆ«å¦‚å›¾fã€‚</p>
<p>èšç±»ç®—æ³•æ˜¯æœ€å¸¸è§çš„æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œè€ŒK-Meansç®—æ³•æ˜¯æœ€å¸¸è§çš„èšç±»ç®—æ³•</p>
<p>EMç®—æ³•æ˜¯ä¸€ä¸ªè¿­ä»£å¼çš„ç®—æ³•ï¼Œåˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šEæ­¥å’ŒMæ­¥ï¼›EMç®—æ³•ä¹Ÿå¯ä»¥è§†ä¸ºå°†ç›®æ ‡å‡½æ•°ä½œåæ ‡ä¸Šå‡çš„è¿‡ç¨‹ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½æ˜¯å›ºå®šä¸€ä¸ªå‚æ•°å¹¶ä¼°è®¡å¦ä¸€ä¸ªå‚æ•°</p>
<p>EMç®—æ³•å’ŒK-Meansç®—æ³•çš„è¿­ä»£è¿‡ç¨‹æ¯”è¾ƒç±»ä¼¼ï¼Œä¸åŒçš„æ˜¯K-Meansç®—æ³•ä¸­æ¯æ¬¡å¯¹å‚æ•°çš„æ›´æ–°æ˜¯ç¡¬çŒœæµ‹ï¼Œè€ŒEMä¸­æ¯æ¬¡å¯¹å‚æ•°çš„æ›´æ–°æ˜¯è½¯çŒœæµ‹ï¼›ç›¸åŒçš„æ˜¯ï¼Œä¸¤ä¸ªç®—æ³•éƒ½å¯èƒ½å¾—åˆ°å±€éƒ¨æœ€ä¼˜è§£ï¼Œé‡‡ç”¨ä¸åŒçš„åˆå§‹å‚æ•°è¿­ä»£ä¼šæœ‰åˆ©äºå¾—åˆ°å…¨å±€æœ€ä¼˜è§£</p>
<h2 id="nearest-neighbors">Nearest Neighbors</h2>
<p>(æ‘˜å½•äºå®˜ç½‘ç½‘ç«™)</p>
<p>æ— ç›‘ç£å­¦ä¹ </p>
<blockquote>
<p><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors"><code>sklearn.neighbors</code></a> provides functionality for unsupervised and supervised neighbors-based learning methods. Unsupervised nearest neighbors is the foundation of many other learning methods, notably manifold learning and spectral clustering. Supervised neighbors-based learning comes in two flavors: <a href="https://scikit-learn.org/stable/modules/neighbors.html#classification">classification</a> for data with discrete labels, and <a href="https://scikit-learn.org/stable/modules/neighbors.html#regression">regression</a> for data with continuous labels.</p>
</blockquote>
<p>Nearest Neighbors Classification</p>
<blockquote>
<p>Neighbors-based classification is a type of <em>instance-based learning</em> or <em>non-generalizing learning</em>: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</p>
</blockquote>
<p>Nearest Neighbors Regression</p>
<blockquote>
<p>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</p>
</blockquote>
<p>Nearest Neighbor Algorithms</p>
<blockquote>
<p>Fast computation of nearest neighbors is an active area of research in machine learning. The most naive neighbor search implementation involves the brute-force computation of distances between all pairs of points in the dataset: for N samples in D dimensions, this approach scales as O[DN2]. Efficient brute-force neighbors searches can be very competitive for small data samples. However, as the number of samples N grows, the brute-force approach quickly becomes infeasible. In the classes within <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors"><code>sklearn.neighbors</code></a>, brute-force neighbors searches are specified using the keyword <code>algorithm = 'brute'</code>, and are computed using the routines available in <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise"><code>sklearn.metrics.pairwise</code></a>.</p>
</blockquote>
<p>æœ‰ä¸‰ç§ç®—æ³•ï¼š</p>
<p>Brute Force</p>
<p>K-D Tree</p>
<p>Ball Tree</p>
<p>Neighborhood Components Analysis</p>
<blockquote>
<p>Combined with a nearest neighbors classifier (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"><code>KNeighborsClassifier</code></a>), NCA is attractive for classification because it can naturally handle multi-class problems without any increase in the model size, and does not introduce additional parameters that require fine-tuning by the user.</p>
<p>Dimensionality reduction ï¼ˆåœ¨é¡¹ç›®ä¸­ä½¿ç”¨çš„å°±æ˜¯è¯¥æŠ€æœ¯ï¼‰</p>
<p>NCA can be used to perform supervised dimensionality reduction. The input data are projected onto a linear subspace consisting of the directions which minimize the NCA objective.</p>
</blockquote>
<p>ï¼ˆå¯ä»¥è¿›ä¸€æ­¥æ¯”è¾ƒä¸€ä¸‹ NCAã€PCA å’Œt-sne çš„åŒºåˆ«å’Œè”ç³»ï¼‰</p>
<p>å‚è€ƒèµ„æ–™ï¼š</p>
<p><a href="https://scikit-learn.org/stable/modules/neighbors.html">Nearest Neighbors</a></p>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">æ–‡ç« ä½œè€…</span>
    <span class="item-content">jijeng</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">ä¸Šæ¬¡æ›´æ–°</span>
    <span class="item-content">
        2020-04-18
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">èµèµæ”¯æŒ</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="http://47.94.35.231:9998/blog_imgs/wechatpay.png">
        <span>å¾®ä¿¡æ‰“èµ</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="http://47.94.35.231:9998/blog_imgs/alipay.png">
        <span>æ”¯ä»˜å®æ‰“èµ</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/cluster/">cluster</a>
          <a href="/tags/%E8%81%9A%E7%B1%BB/">èšç±»</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/macos_tutorial/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default"> Mac OS ä½¿ç”¨tutorial</span>
            <span class="prev-text nav-mobile">ä¸Šä¸€ç¯‡</span>
          </a>
        <a class="next" href="/post/cnn_understanding/">
            <span class="next-text nav-default">CNN Understanding</span>
            <span class="next-text nav-mobile">ä¸‹ä¸€ç¯‡</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="http://jijeng.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    ç”± <a class="hexo-link" href="https://gohugo.io">Hugo</a> å¼ºåŠ›é©±åŠ¨
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    ä¸»é¢˜ - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2018 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span>jijeng</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
