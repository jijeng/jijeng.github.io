<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>CNN Understanding - Jijeng&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="jijeng" /><meta name="description" content="CNN 网络中常见层的介绍和理解。
" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.79.1 with theme even" />


<link rel="canonical" href="http://jijeng.github.io/post/cnn_understanding/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.c7bc1becf36bcf6a9ebd25d2947e43a2eb745ddb0c9a32b43126fd7fa460c351.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="CNN Understanding" />
<meta property="og:description" content="CNN 网络中常见层的介绍和理解。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://jijeng.github.io/post/cnn_understanding/" />
<meta property="article:published_time" content="2020-04-07T10:41:47+08:00" />
<meta property="article:modified_time" content="2020-04-07T10:41:47+08:00" />
<meta itemprop="name" content="CNN Understanding">
<meta itemprop="description" content="CNN 网络中常见层的介绍和理解。">
<meta itemprop="datePublished" content="2020-04-07T10:41:47+08:00" />
<meta itemprop="dateModified" content="2020-04-07T10:41:47+08:00" />
<meta itemprop="wordCount" content="4663">



<meta itemprop="keywords" content="cnn," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CNN Understanding"/>
<meta name="twitter:description" content="CNN 网络中常见层的介绍和理解。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Jijeng&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Jijeng&#39;s Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">CNN Understanding</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-04-07 </span>
        <div class="post-category">
            <a href="/categories/deep-learning/"> deep learning </a>
            </div>
          <span class="more-meta"> 约 4663 字 </span>
          <span class="more-meta"> 预计阅读 10 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>CNN 网络中常见层的介绍和理解。</p>
<p>一、边界检测（引子）</p>
<p>通过设计某个滤波器（filter，也可以称为 kernel），去和图像做卷积操作，可以发现图像中的某些特征。CNN 就是通过一个个 filter， 不断提取特征，从局部的特征到整体的特征，从而完成了图像识别的功能。</p>
<p>二、CNN 中的基本概念</p>
<p>CNN网络中常见的结构是：卷积、池化和激活。卷积层是CNN 网络的核心，激活函数获得非线性特征，池化层主要体现在降采样：保留显著特征、降低特征的维度、扩大 kernel 的感受野。</p>
<p>pooling 可以提供旋转不变性?</p>
<blockquote>
<p>更加准确的是说 max pooling 具有微小形变的鲁棒性。当我们正面拍一些图像，在某些地方得到 activation，然后旋转一定的角度，依然能够在这个点得到 activation。这个其实 maxpooling 的决定的。</p>
</blockquote>
<ol>
<li>padding 填白</li>
</ol>
<p>从上面的引子中，我们可以知道，原图像在经过filter卷积之后，变小了，从(8,8)变成了(6,6)。假设我们再卷一次，那大小就变成了(4,4)了。这样有啥问题呢？ 主要有两个问题：</p>
<ul>
<li>每次卷积，图像都缩小，这样卷不了几次就没了；</li>
<li>相比于图片中间的点，图片边缘的点在卷积中被计算的次数很少。这样的话，边缘的信息就易于丢失。</li>
</ul>
<p>为了解决这个问题，我们可以采用padding的方法。我们每次卷积前，先给图片周围都补一圈空白，让卷积之后图片跟原来一样大，同时，原来的边缘也被计算了更多次。</p>
<p>我们把上面这种“让卷积之后的大小不变”的padding方式，称为 “Same”方式， 把不经过任何填白的，称为 “Valid”方式。这个是我们在使用一些框架的时候，需要设置的超参数。</p>
<ol start="2">
<li>stride 步长</li>
</ol>
<p>前面我们所介绍的卷积，都是默认步长是1，但实际上，我们可以设置步长为其他的值。</p>
<p>3.pooling 池化</p>
<p>这个pooling，是为了提取一定区域的主要特征，并减少参数数量，防止模型过拟合。 除了MaxPooling,还有AveragePooling，顾名思义就是取那个区域的平均值。</p>
<p>global average pooling or global max pooling</p>
<p>GAP 可以实现任意图像大小的输入。</p>
<p>global average pooling 和 average pooling （local）的差别在于 global，local 是取feature map 上的一个子区域求均值和最大值，然后滑动子区域；global 就是针对整个 feature map 求解均值和最大值。</p>
<p>Global Pooling就是<strong>池化窗口的大小 = 整张特征图的大小</strong>。这样，每个 W×H×C 的特征图输入就会被转化为 1×1×C 的输出，也等同于每个位置权重都为 1/(W×H) 的全连接层操作。</p>
<p>使用全局池化之后，特征图每个 channel 都被压缩成了一个点，实际上是对没给个channel 进行了信息压缩。</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/25/1576078449-7190--700x298.jpg" alt="关于global average pooling理解和介绍"></p>
<p>4.对多通道（channels）图片的卷积</p>
<p>如果输入图片是三维的呢（即增多了一个channels），比如是(8,8,3)，这个时候，我们的filter的维度就要变成(3,3,3)了，它的 最后一维要跟输入的channel维度一致。 这个时候的卷积，是三个channel的所有元素对应相乘后求和，也就是之前是9个乘积的和，现在是27个乘积的和。因此，输出的维度并不会变化。还是(6,6)。</p>
<p>但是，一般情况下，我们会 使用多了filters同时卷积，比如，如果我们同时使用4个filter的话，那么 输出的维度则会变为(6,6,4)。</p>
<p>三、CNN的结构组成</p>
<ol>
<li>
<p>Convolutional layer（卷积层&ndash;CONV）</p>
</li>
<li>
<p>Pooling layer （池化层&ndash;POOL）</p>
</li>
</ol>
<blockquote>
<p>Pooling layers are generally used to reduce the size of the inputs and hence speed up the computation.</p>
</blockquote>
<img src="http://123.56.8.10:8899/images/2021/03/25/6ngw4u.png" width="80%" height="80%">
<p>注意这里的 filter size 是2， 然后stride 是2.</p>
<p>In summary, the hyperparameters for a pooling layer are:</p>
<ul>
<li>Filter size</li>
<li>Stride</li>
<li>Max or average pooling</li>
</ul>
<p>CNN 中 stride、kernel、padding 的计算</p>
<p>定义以下参数定义 <img src="https://www.zhihu.com/equation?tex=stride++%3D+S" alt="[公式]">,  <img src="https://www.zhihu.com/equation?tex=kernelsize+%3D+F%28kernel++size+%3D+F+%2AF%29+" alt="[公式]">, <img src="https://www.zhihu.com/equation?tex=padding+%3D+P+" alt="[公式]"></p>
<p>输入尺寸为 <img src="https://www.zhihu.com/equation?tex=W" alt="[公式]"></p>
<p>输出尺寸为 <img src="https://www.zhihu.com/equation?tex=W_%7Bnew%7D" alt="[公式]"></p>
<p>则有卷积尺寸变化为
$$
W_{n e w}=\frac{W-F+2 * P}{S}+1
$$</p>
<p>比如，输入是28，卷积核是$3*3$, 步长 stride为 1，padding 为1，通过上述的公式得到新的输出是 28。和原来的输入是一样的。</p>
<ol start="3">
<li>Fully Connected layer（全连接层&ndash;FC）</li>
</ol>
<img src="http://123.56.8.10:8899/images/2021/03/25/GRcq81.png" width="80%" height="80%">
<p>这里需要说明的是，在经过数次卷积和池化之后，我们 最后会先将多维的数据进行“扁平化”，也就是把 (height,width,channel)的数据压缩成长度为 height × width × channel 的一维数组，然后再与 FC层连接，这之后就跟普通的神经网络无异了。</p>
<ol start="4">
<li>Batch normalization &amp; ReLU</li>
</ol>
<blockquote>
<p>After applying filters on the input, we apply a batch normalization followed by a ReLU for non-linearity. The batch normalization renormalizes data to make learning faster with the Gradient descent.
使用batch normalization是为了 learn faster（gradient descent）； 使用 relu 是为了增加非线性</p>
</blockquote>
<p>全连接层过多的参数会导致过拟合，所以有一些专门的方法去解决过拟合，比如说 dropout。</p>
<p>四、卷积网络 VS. 传统神经网络</p>
<p>卷积网络相比于传统神经网络有两点好处：</p>
<p>1.参数共享机制（parameters sharing）</p>
<p>参数共享机制，让我们的网络的参数数量大大地减少。<a href="https://zhuanlan.zhihu.com/p/42559190">从此明白了卷积神经网络（CNN）</a></p>
<ol start="2">
<li>连接的稀疏性（sparsity of connections）</li>
</ol>
<p>由卷积的操作可知，输出图像中的任何一个单元，只跟输入图像的一部分有关系：</p>
<p>Computer Vision 中常见的是以下三类问题：</p>
<ul>
<li>Image classification</li>
<li>Object detection</li>
<li>Neural style transfer</li>
</ul>
<p>1D convolution is covered here, because it’s usually under-explained, but it has noteworthy benefits.</p>
<blockquote>
<p>They are used to reduce the depth (number of channels). Width and height are unchanged in this case. If you want to reduce the horizontal dimensions, you would use pooling, increase the stride of the convolution, or don’t add paddings. The 1D convolutions computes a weighted sum of input channels or features, which allow selecting certain combinations of features that are useful downstream.
可以降低 number of channels （depth），而不改变 width or height。如果想要改变该尺寸，那么使用 pooling 技术</p>
</blockquote>
<p>CNN 概念介绍</p>
<p>alexnet</p>
<p><img src="http://47.94.35.231:9998/blog_imgs/image-20201119163445214.png" alt="image-20201119163445214" style="zoom:50%;" /></p>
<p>卷积简单说是相乘然后累加求和。</p>
<p>卷积填充中的mode： valid，same，full。valid：不进行填充；same：是以卷积核的中心和图像array的左上角进行对齐；full：以卷积核的右下角和图像array的左上角对齐。</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/25/image-20201119163722313.png" alt="image-20201119163722313" style="zoom:50%;" /></p>
<p><strong>卷积核</strong></p>
<p>水平卷积核识别横线</p>
<p>垂直卷积核识别竖线</p>
<p>Scharr边界更加锐利</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/25/image-20201119171813112.png" alt="image-20201119171813112" style="zoom:50%;" /></p>
<p>所以卷积核是否能够识别，归结为“物以类聚”。如果卷积核形状和图像的物体形状相似，那么是容易识别；如果相反，那么不容易识别。</p>
<p>传统的CNN 结构</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/25/image-20201119173233995.png" alt="image-20201119173233995" style="zoom:50%;" /></p>
<p>同一图像输入，用不同的卷积核得到的是不同的结果，但其中也有一些类似的地方。</p>
<p>为什么深层次的网络识别效果好？</p>
<ul>
<li>深层次网络的 receptive （感受野）更大</li>
<li>浅层次的特征可以汇聚成更复杂的特征</li>
</ul>
<p>pooling: 降采样的操作，提高效率（特征数量减少）；使得某些特征更健壮。</p>
<p>dropout 中的 <code>keep_prob=1</code> 表示保留全部的数据； <code>keep_prob=0</code> 表示全部丢弃数据。注意其余的数据还需要进行<code>1/keep_prob</code> ，以保证和不变。</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/25/image-20201127164513099.png" alt="image-20201127164513099" style="zoom:70%;" /></p>
<p>在卷积网络中一般倾向于使用多个小的卷积核而不是一个大的卷积核。原因：参数量 $7<em>7 &gt; 3</em>3*3$；多层卷积核可以引入非线性。</p>
<p>adam 对于不同的参数使用不同的学习率；BGD 对于不同的参数使用相同的学习率。所以建议使用 adam 作为optim。</p>
<p>图像识别的实质仍然是分类，进一步的工作就是目标检测。（如果图像分类做好了，那么是可以去做目标检测）。object detection的演变流程：</p>
<ul>
<li>R-CNN： region-CNN， 首先是对于图像处理得到若干CNN 能够直接处理的小图，然后每个图进行得到的embedding +svm 得到该小框物体的置信度，执行度最大的话就是最后的结果。</li>
<li>Fast R-CNN：首先图像过一个CNN得到feature map，然后提取region 中相应的feature，feature +svm 得到置信度。这样共享了 feature map，大大提高了时间效率。（解决的是多次计算CNN 的效率问题）</li>
<li>Faster R-CNN：首先图像过CNN得到feature map，然后通过<code>region proposel network</code> 从CNN 中得到框，然后通过一个 classifer得到置信度。（解决的是计算 region的效率问题）</li>
</ul>
<p><strong>Separable Convolution卷积层（来自mobilenet）</strong></p>
<p>Separable Convolution的卷积运算方式。它将传统卷积分解为Depthwise Convolution与Pointwise Convolution两部分，有效的减小了参数数量。主要是为了适应移动端设备的性能。</p>
<p>下面给出一个例子说明。</p>
<p>此时，卷积层共4个Filter，每个Filter包含了3个Kernel，每个Kernel的大小为3×3。因此卷积层的参数数量可以用如下公式来计算：</p>
<p>核心思想是将一个完整的卷积运算分解为两步进行，Depthwise Convolution与Pointwise Convolution。</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/31/image-20210331140611578.png" alt="image-20210331140611578" style="zoom:50%;" /></p>
<p>Depthwise Convolution完成后的Feature map数量与输入层的depth相同，但是这种运算对输入层的每个channel独立进行卷积运算后就结束了，没有有效的利用不同map在相同空间位置上的信息。因此需要增加另外一步操作来将这些map进行组合生成新的Feature map，即接下来的Pointwise Convolution。</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/31/image-20210331140531938.png" alt="image-20210331140531938" style="zoom:50%;" /></p>
<p>Pointwise Convolution的运算与常规卷积运算非常相似，不同之处在于卷积核的尺寸为 1×1×M，M为上一层的depth。所以这里的卷积运算会将上一步的map在深度方向上进行加权组合，生成新的Feature map。</p>
<p>对比一下两个的参数量：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 第一种
N_std = 4 × 3 × 3 × 3 = 108
# 第二种
N_depthwise = 3 × 3 × 3 = 27
N_pointwise = 1 × 1 × 3 × 4 = 12
N_separable = N_depthwise + N_pointwise = 39
</code></pre></td></tr></table>
</div>
</div><p>所以同样是 4 个feature map， separable convolution 的参数个数基本上是常规卷积的 $1/3$。</p>
<p>但 Separable Convolution 也不是没有缺点，使用该卷积的网络结构在 train 的时候占用显存比较大。</p>
<blockquote>
<p>efficientnet 的模型很小，因为本地保存的模型 ckpt 容量代销和模型的参数量相关，模型参数和模型自身 layer 的设计有关，但是模型训练时占用的显存不是和模型参数量成一定的线性关系，更多的是和模型 inference 与 backward 过程中产生的 feature map 大小有关，另外和网络的深度也有一定的关系（这样中间变量可能更多了），在 backward 的时候更是直接翻倍，因为需要保存特征图的梯度，可能需要 2 倍的显存占用。</p>
<p>同时网络中的多分支也是比较消耗内存的，参考凯明大佬的regnet</p>
</blockquote>
<p><img src="http://123.56.8.10:8899/images/2021/03/31/v2-7ff329bfba3195dcb094651605ecd5eb_1440w8c7f344b7be86c34.jpg" alt="img" style="zoom:50%;" /></p>
<p>参考文献</p>
<p><a href="https://zhuanlan.zhihu.com/p/80041030">Depthwise卷积与Pointwise卷积</a></p>
<p><a href="https://yinguobing.com/separable-convolution/">卷积神经网络中的Separable Convolution</a></p>
<p><a href="https://www.zhihu.com/question/388773309">EfficientDet和EfficientNet的模型很小，为什么占用的显存很高呢?</a></p>
<p>空洞卷积</p>
<p>Dilation卷积，通常译作空洞卷积或者卷积核膨胀操作，它是解决pixel-wise输出模型的一种常用的卷积方式。一种普遍的认识是，pooling下采样操作导致的信息丢失是不可逆的，通常的分类识别模型，只需要预测每一类的概率，所以我们不需要考虑pooling会导致损失图像细节信息的问题，但是做像素级的预测时（譬如语义分割），就要考虑到这个问题了。</p>
<blockquote>
<p>提出的主要是为了解决采用 pooling 操作导致的信息损失的问题。空洞卷积的好处是在不做 pooling损失函数的情况下，增加了感受野。在图像需要全局信息，都能很好的应用空洞卷积，比如图像分割。</p>
</blockquote>
<p>所以就要有一种卷积代替pooling的作用（成倍的增加感受野），而空洞卷积就是为了做这个的。通过卷积核插“0”的方式，它可以比普通的卷积获得更大的感受野，这个idea的motivation就介绍到这里。</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/31/v2-4959201e816888c6648f2e78cccfd253_hd.gif" alt=""></p>
<p>下面是常规的卷积操作</p>
<p><img src="http://123.56.8.10:8899/images/2021/03/31/v2-d552433faa8363df84c53b905443a556_hd.gif" alt="img"></p>
<p><strong>反卷积和上采样的区别</strong></p>
<p>转置卷积 (transposed convolution) 又称为反卷积（Deconvolution）。可以理解为卷积的逆过程，实现上采用转置卷积核的方式。</p>
<p>普通的卷积和池化会缩小图像的尺寸，有时候为了得到和原图等大的分割图，需要进行上采样卷积。</p>
<p><img src="http://123.56.8.10:8899/images/2021/04/26/1EF52InXEbUhf12149452e9f1f39.gif" alt="img"></p>
<p>从卷积到转置卷积的理解可以查看这里：https://www.malaoshi.top/show_1EF52HLXBmqf.html</p>
<p>（对于反卷积，以下有不同的形态）</p>
<p><img src="http://123.56.8.10:8899/images/2021/04/26/njW8CF.gif" alt="transposed convolution"></p>
<p>反卷积的使用场景一般在语义分割和生成模型（比如说GAN ）中使用较多。</p>
<p>upPooling： 当upPooling 的时候填充的是0。</p>
<p>（这里针对MaxPooling）可以看到UnPooling操作相当于在进行MaxPooling操作时候对局部最大值的出现位置进行了记录，然后在反向过程补全的时候将最大值填充回原处，然后剩余的地方全部填充零。</p>
<blockquote>
<p>这个是需要记录位置的</p>
</blockquote>
<p><img src="http://123.56.8.10:8899/images/2021/04/26/image-20210426170024653.png" alt="UpPooling"></p>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">jijeng</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2020-04-07
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="http://47.94.35.231:9998/blog_imgs/wechatpay.png">
        <span>微信打赏</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="http://47.94.35.231:9998/blog_imgs/alipay.png">
        <span>支付宝打赏</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/cnn/">cnn</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/cluster_algorithm/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Cluster algorithm</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/gpu/">
            <span class="next-text nav-default">深度学习中的 GPU</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="http://jijeng.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2018 - 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>jijeng</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
